# ===================================================================
# 模型定义 (Models)
# ===================================================================
# 在这里定义所有可用的模型。每个模型都需要一个唯一的标识符（如 gpt_4o）。
#
# 参数说明:
#   provider: 模型的提供商类型。支持:
#             - "openai": 标准OpenAI模型
#             - "anthropic": Anthropic Claude模型
#             - "google": Google Gemini模型
#             - "openai_compatible": 任何兼容OpenAI API格式的自定义模型
#   model_name: 要传递给API的实际模型名称。
#   api_key_env: (可选) 用于此模型的API密钥的环境变量名称。
#                如果未提供，将默认使用 "OPENAI_API_KEY", "ANTHROPIC_API_KEY", "GOOGLE_API_KEY"。
#   base_url_env: (仅用于 openai_compatible) 用于此模型的base_url的环境变量名称。
#
models:
  gpt_4o:
    provider: "openai"
    model_name: "gpt-4o"

  gpt_3_5_turbo:
    provider: "openai"
    model_name: "gpt-3.5-turbo"

  claude_3_opus:
    provider: "anthropic"
    model_name: "claude-3-opus-20240229"

  claude_3_haiku:
    provider: "anthropic"
    model_name: "claude-3-haiku-20240307"

  gemini_1_5_flash:
    provider: "google"
    model_name: "gemini-1.5-flash-latest"

  ernie-5.0-thinking-preview:
    provider: "qianfan"
    model_name: "ernie-5.0-thinking-preview"

  # --- 在这里添加您的自定义模型 ---
  # 例如，下面是火山方舟豆包模型的配置
  doubao_seed:
    provider: "openai_compatible"
    model_name: "doubao-seed-1-6-251015"
    api_key_env: "DOUBAO_CUSTOM_API_KEY" # 在 .env 文件中定义
    base_url_env: "DOUBAO_CUSTOM_BASE_URL" # 在 .env 文件中定义


# ===================================================================
# 步骤到模型的映射 (Steps to Models Mapping)
# ===================================================================
# 在这里将项目工作流中的每一步映射到上面定义的模型标识符。
# 您可以自由地为任何步骤分配任何已定义的模型。
#
steps:
  # planner: "gpt_4o"
  # researcher: "claude_3_haiku"
  # summarizer: "gemini_1_5_flash"
  # outliner: "gpt_4o"
  # drafter: "gpt_3_5_turbo"
  # reviser: "claude_3_opus"

  # --- 如果您想使用豆包模型进行测试，可以取消下面的注释 ---
  planner: "doubao_seed"
  drafter: "doubao_seed"

# ===================================================================
# Embedding 模型定义
# ===================================================================
embeddings:
  openai_embedding:
    template: "openai"
    model: "text-embedding-3-small"
    api_key_env: "OPENAI_API_KEY"
  
  ollama_embedding:
    template: "ollama"
    model: "mxbai-embed-large"
    base_url_env: "OLLAMA_BASE_URL"

  google_embedding:
    template: "google_genai"
    model: "models/embedding-001"
    api_key_env: "GOOGLE_API_KEY"

  local_bge_embedding:
    template: "huggingface"
    model_name: "BAAI/bge-small-zh-v1.5"

# 指定当前激活的 embedding 模型
active_embedding_model: "local_bge_embedding"

# ===================================================================
# RAG 检索参数 (RAG Retrieval Parameters)
# ===================================================================
# 在这里配置RAG流程中的检索参数。
#
# 参数说明:
#   recall_k: 在向量数据库中进行相似度搜索时，初始召回的文档数量。
#             这个值应该足够大，以确保相关文档被包含在内，但也不要太大以免增加不必要的计算负担。
#   rerank_k: 在使用重排序器（Re-ranker）对召回的文档进行重新排序后，最终保留的最相关的文档数量。
#             这个值决定了最终注入到LLM上下文中的文档数量。
#
rag:
  recall_k: 20
  rerank_k: 5


